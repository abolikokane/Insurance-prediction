2023-04-17 18:33:23,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:33:23,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:33:23,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:33:23,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:33:25,800:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-17 18:33:28,821:INFO:PyCaret RegressionExperiment
2023-04-17 18:33:28,821:INFO:Logging name: reg-default-name
2023-04-17 18:33:28,821:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-17 18:33:28,821:INFO:version 3.0.0
2023-04-17 18:33:28,821:INFO:Initializing setup()
2023-04-17 18:33:28,822:INFO:self.USI: 0883
2023-04-17 18:33:28,822:INFO:self._variable_keys: {'y', 'y_test', 'logging_param', 'html_param', 'idx', 'y_train', 'fold_generator', 'transform_target_param', 'gpu_param', 'exp_id', '_available_plots', 'seed', '_ml_usecase', 'data', 'fold_shuffle_param', 'exp_name_log', 'memory', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'USI', 'X', 'X_test', 'target_param', 'fold_groups_param', 'n_jobs_param', 'X_train'}
2023-04-17 18:33:28,822:INFO:Checking environment
2023-04-17 18:33:28,822:INFO:python_version: 3.10.9
2023-04-17 18:33:28,822:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2023-04-17 18:33:28,823:INFO:machine: AMD64
2023-04-17 18:33:28,849:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-17 18:33:28,856:INFO:Memory: svmem(total=7866445824, available=457502720, percent=94.2, used=7408943104, free=457502720)
2023-04-17 18:33:28,856:INFO:Physical Core: 6
2023-04-17 18:33:28,856:INFO:Logical Core: 12
2023-04-17 18:33:28,856:INFO:Checking libraries
2023-04-17 18:33:28,857:INFO:System:
2023-04-17 18:33:28,857:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2023-04-17 18:33:28,857:INFO:executable: C:\Users\aboli\AppData\Local\Programs\Python\Python310\python.exe
2023-04-17 18:33:28,857:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-17 18:33:28,857:INFO:PyCaret required dependencies:
2023-04-17 18:33:28,857:INFO:                 pip: 23.0.1
2023-04-17 18:33:28,857:INFO:          setuptools: 65.5.0
2023-04-17 18:33:28,857:INFO:             pycaret: 3.0.0
2023-04-17 18:33:28,857:INFO:             IPython: 8.12.0
2023-04-17 18:33:28,857:INFO:          ipywidgets: 8.0.6
2023-04-17 18:33:28,857:INFO:                tqdm: 4.65.0
2023-04-17 18:33:28,858:INFO:               numpy: 1.23.5
2023-04-17 18:33:28,858:INFO:              pandas: 1.5.3
2023-04-17 18:33:28,858:INFO:              jinja2: 3.1.2
2023-04-17 18:33:28,858:INFO:               scipy: 1.10.1
2023-04-17 18:33:28,858:INFO:              joblib: 1.2.0
2023-04-17 18:33:28,858:INFO:             sklearn: 1.2.2
2023-04-17 18:33:28,858:INFO:                pyod: 1.0.9
2023-04-17 18:33:28,858:INFO:            imblearn: 0.10.1
2023-04-17 18:33:28,858:INFO:   category_encoders: 2.6.0
2023-04-17 18:33:28,858:INFO:            lightgbm: 3.3.5
2023-04-17 18:33:28,858:INFO:               numba: 0.56.4
2023-04-17 18:33:28,858:INFO:            requests: 2.28.2
2023-04-17 18:33:28,858:INFO:          matplotlib: 3.7.1
2023-04-17 18:33:28,858:INFO:          scikitplot: 0.3.7
2023-04-17 18:33:28,858:INFO:         yellowbrick: 1.5
2023-04-17 18:33:28,858:INFO:              plotly: 5.14.1
2023-04-17 18:33:28,858:INFO:             kaleido: 0.2.1
2023-04-17 18:33:28,858:INFO:         statsmodels: 0.13.5
2023-04-17 18:33:28,858:INFO:              sktime: 0.17.1
2023-04-17 18:33:28,858:INFO:               tbats: 1.1.2
2023-04-17 18:33:28,858:INFO:            pmdarima: 2.0.3
2023-04-17 18:33:28,858:INFO:              psutil: 5.9.4
2023-04-17 18:33:28,860:INFO:PyCaret optional dependencies:
2023-04-17 18:33:28,877:INFO:                shap: Not installed
2023-04-17 18:33:28,877:INFO:           interpret: Not installed
2023-04-17 18:33:28,877:INFO:                umap: Not installed
2023-04-17 18:33:28,877:INFO:    pandas_profiling: Not installed
2023-04-17 18:33:28,877:INFO:  explainerdashboard: Not installed
2023-04-17 18:33:28,877:INFO:             autoviz: Not installed
2023-04-17 18:33:28,877:INFO:           fairlearn: Not installed
2023-04-17 18:33:28,877:INFO:             xgboost: Not installed
2023-04-17 18:33:28,877:INFO:            catboost: Not installed
2023-04-17 18:33:28,877:INFO:              kmodes: Not installed
2023-04-17 18:33:28,877:INFO:             mlxtend: Not installed
2023-04-17 18:33:28,877:INFO:       statsforecast: Not installed
2023-04-17 18:33:28,877:INFO:        tune_sklearn: Not installed
2023-04-17 18:33:28,877:INFO:                 ray: Not installed
2023-04-17 18:33:28,877:INFO:            hyperopt: Not installed
2023-04-17 18:33:28,877:INFO:              optuna: Not installed
2023-04-17 18:33:28,877:INFO:               skopt: Not installed
2023-04-17 18:33:28,878:INFO:              mlflow: Not installed
2023-04-17 18:33:28,878:INFO:              gradio: Not installed
2023-04-17 18:33:28,878:INFO:             fastapi: Not installed
2023-04-17 18:33:28,878:INFO:             uvicorn: Not installed
2023-04-17 18:33:28,878:INFO:              m2cgen: Not installed
2023-04-17 18:33:28,878:INFO:           evidently: Not installed
2023-04-17 18:33:28,878:INFO:               fugue: Not installed
2023-04-17 18:33:28,878:INFO:           streamlit: 1.21.0
2023-04-17 18:33:28,878:INFO:             prophet: Not installed
2023-04-17 18:33:28,878:INFO:None
2023-04-17 18:33:28,878:INFO:Set up data.
2023-04-17 18:33:28,892:INFO:Set up train/test split.
2023-04-17 18:33:28,901:INFO:Set up index.
2023-04-17 18:33:28,902:INFO:Set up folding strategy.
2023-04-17 18:33:28,902:INFO:Assigning column types.
2023-04-17 18:33:28,907:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-17 18:33:28,907:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-17 18:33:28,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:33:28,920:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:33:28,996:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,095:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,101:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,236:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-17 18:33:29,242:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,248:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,382:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,388:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,458:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,515:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-17 18:33:29,527:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,808:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-17 18:33:29,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:29,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:29,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:30,084:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:33:30,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,086:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-17 18:33:30,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:30,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:33:30,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,358:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-17 18:33:30,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:30,634:INFO:Preparing preprocessing pipeline...
2023-04-17 18:33:30,634:INFO:Set up simple imputation.
2023-04-17 18:33:30,703:INFO:Set up encoding of ordinal features.
2023-04-17 18:33:30,707:INFO:Set up encoding of categorical features.
2023-04-17 18:33:30,707:INFO:Set up feature normalization.
2023-04-17 18:33:30,833:INFO:Finished creating preprocessing pipeline.
2023-04-17 18:33:30,889:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-17 18:33:30,889:INFO:Creating final display dataframe.
2023-04-17 18:33:31,174:INFO:Setup _display_container:                     Description             Value
0                    Session id              7402
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape        (1070, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              0883
2023-04-17 18:33:31,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:31,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:31,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:31,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:33:31,478:INFO:setup() successfully completed in 3.03s...............
2023-04-17 18:33:31,478:INFO:Initializing create_model()
2023-04-17 18:33:31,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4E2BFA6E0>, estimator=gbr, fold=10, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-17 18:33:31,478:INFO:Checking exceptions
2023-04-17 18:33:31,482:INFO:Importing libraries
2023-04-17 18:33:31,482:INFO:Copying training dataset
2023-04-17 18:33:31,488:INFO:Defining folds
2023-04-17 18:33:31,488:INFO:Declaring metric variables
2023-04-17 18:33:31,488:INFO:Importing untrained model
2023-04-17 18:33:31,488:INFO:Gradient Boosting Regressor Imported successfully
2023-04-17 18:33:31,488:INFO:Starting cross validation
2023-04-17 18:33:31,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-17 18:33:45,625:INFO:Calculating mean and std
2023-04-17 18:33:45,627:INFO:Creating metrics dataframe
2023-04-17 18:33:45,631:INFO:Finalizing model
2023-04-17 18:33:46,426:INFO:Uploading results into container
2023-04-17 18:33:46,427:INFO:Uploading model into container now
2023-04-17 18:33:46,437:INFO:_master_model_container: 1
2023-04-17 18:33:46,437:INFO:_display_container: 2
2023-04-17 18:33:46,438:INFO:GradientBoostingRegressor(random_state=7402)
2023-04-17 18:33:46,438:INFO:create_model() successfully completed......................................
2023-04-17 18:33:46,531:INFO:Initializing tune_model()
2023-04-17 18:33:46,531:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=7402), fold=10, round=4, n_iter=30, custom_grid={'learning_rate': [0.01, 0.02, 0.05], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8], 'subsample': [0.4, 0.5, 0.6, 0.7, 0.8], 'n_estimators': [100, 200.3, 400, 500, 600]}, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001C4E2BFA6E0>)
2023-04-17 18:33:46,531:INFO:Checking exceptions
2023-04-17 18:33:46,534:INFO:Copying training dataset
2023-04-17 18:33:46,536:INFO:Checking base model
2023-04-17 18:33:46,536:INFO:Base model : Gradient Boosting Regressor
2023-04-17 18:33:46,537:INFO:Declaring metric variables
2023-04-17 18:33:46,537:INFO:Defining Hyperparameters
2023-04-17 18:33:46,619:INFO:custom_grid: {'actual_estimator__learning_rate': [0.01, 0.02, 0.05], 'actual_estimator__max_depth': [1, 2, 3, 4, 5, 6, 7, 8], 'actual_estimator__subsample': [0.4, 0.5, 0.6, 0.7, 0.8], 'actual_estimator__n_estimators': [100, 200.3, 400, 500, 600]}
2023-04-17 18:33:46,620:INFO:Tuning with n_jobs=-1
2023-04-17 18:33:46,620:INFO:Initializing RandomizedSearchCV
2023-04-17 18:33:49,286:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:49,323:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:50,237:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:50,290:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:50,440:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:50,446:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:50,521:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:50,870:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:51,164:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:51,539:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:51,743:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:51,779:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:51,783:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:51,888:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:52,034:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:52,308:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:52,533:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:53,459:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:55,594:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:55,890:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:56,409:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:56,440:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:56,573:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:56,852:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:56,867:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:57,239:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:57,530:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:57,715:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:57,822:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:33:58,155:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:58,220:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:58,346:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:58,384:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:58,446:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:58,783:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:58,899:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:59,075:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:59,220:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:33:59,803:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:00,513:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:00,516:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:00,526:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:00,688:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:01,556:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:01,676:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:01,711:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:01,749:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:01,930:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:02,396:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:02,401:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:02,490:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:02,877:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:03,065:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:03,425:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:03,510:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:04,232:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:08,302:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:08,710:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:09,069:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:09,149:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:09,802:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:10,044:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:10,303:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:10,587:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:10,809:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:10,832:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:11,362:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:11,495:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:12,130:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:12,212:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:12,229:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:12,490:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:12,741:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:12,889:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:12,961:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:13,226:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:13,732:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:13,734:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:14,118:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:14,732:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:14,767:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:14,981:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:15,283:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:15,613:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:16,197:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:16,256:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:16,810:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:16,963:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:17,098:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:17,629:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:17,694:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:18,387:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:18,624:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:19,092:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:36,663:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:37,291:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:39,569:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:40,424:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:40,458:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:40,787:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:40,898:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:40,927:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:41,000:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:41,027:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:41,141:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:41,181:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:41,317:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:41,347:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:42,367:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:42,610:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:42,696:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:42,763:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:42,879:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:42,980:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:43,019:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:43,035:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:43,040:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:43,166:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:43,512:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:43,622:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:45,466:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:45,779:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:46,053:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:46,150:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:46,194:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:46,250:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:46,258:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:46,786:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:47,506:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:47,579:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:47,923:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:47,948:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:47,963:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:48,030:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:48,082:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:48,733:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:49,235:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:52,244:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:52,619:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-17 18:34:53,050:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:54,278:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:54,837:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:34:55,425:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:37:26,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:37:26,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:37:26,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:37:26,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:37:28,243:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-17 18:37:30,352:INFO:PyCaret RegressionExperiment
2023-04-17 18:37:30,353:INFO:Logging name: reg-default-name
2023-04-17 18:37:30,353:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-17 18:37:30,354:INFO:version 3.0.0
2023-04-17 18:37:30,354:INFO:Initializing setup()
2023-04-17 18:37:30,355:INFO:self.USI: c0b7
2023-04-17 18:37:30,355:INFO:self._variable_keys: {'exp_name_log', 'X_test', 'idx', 'target_param', 'X', 'seed', 'y_test', 'fold_shuffle_param', 'fold_generator', 'html_param', 'USI', 'exp_id', 'pipeline', '_ml_usecase', 'data', 'n_jobs_param', 'gpu_n_jobs_param', 'log_plots_param', 'transform_target_param', 'memory', 'logging_param', 'X_train', 'fold_groups_param', 'y', 'gpu_param', 'y_train', '_available_plots'}
2023-04-17 18:37:30,355:INFO:Checking environment
2023-04-17 18:37:30,355:INFO:python_version: 3.10.9
2023-04-17 18:37:30,356:INFO:python_build: ('tags/v3.10.9:1dd9be6', 'Dec  6 2022 20:01:21')
2023-04-17 18:37:30,356:INFO:machine: AMD64
2023-04-17 18:37:30,374:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-17 18:37:30,382:INFO:Memory: svmem(total=7866445824, available=1876058112, percent=76.2, used=5990387712, free=1876058112)
2023-04-17 18:37:30,383:INFO:Physical Core: 6
2023-04-17 18:37:30,383:INFO:Logical Core: 12
2023-04-17 18:37:30,383:INFO:Checking libraries
2023-04-17 18:37:30,383:INFO:System:
2023-04-17 18:37:30,383:INFO:    python: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
2023-04-17 18:37:30,383:INFO:executable: C:\Users\aboli\AppData\Local\Programs\Python\Python310\python.exe
2023-04-17 18:37:30,383:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-17 18:37:30,383:INFO:PyCaret required dependencies:
2023-04-17 18:37:30,383:INFO:                 pip: 23.0.1
2023-04-17 18:37:30,383:INFO:          setuptools: 65.5.0
2023-04-17 18:37:30,383:INFO:             pycaret: 3.0.0
2023-04-17 18:37:30,383:INFO:             IPython: 8.12.0
2023-04-17 18:37:30,383:INFO:          ipywidgets: 8.0.6
2023-04-17 18:37:30,383:INFO:                tqdm: 4.65.0
2023-04-17 18:37:30,383:INFO:               numpy: 1.23.5
2023-04-17 18:37:30,383:INFO:              pandas: 1.5.3
2023-04-17 18:37:30,383:INFO:              jinja2: 3.1.2
2023-04-17 18:37:30,384:INFO:               scipy: 1.10.1
2023-04-17 18:37:30,384:INFO:              joblib: 1.2.0
2023-04-17 18:37:30,384:INFO:             sklearn: 1.2.2
2023-04-17 18:37:30,384:INFO:                pyod: 1.0.9
2023-04-17 18:37:30,384:INFO:            imblearn: 0.10.1
2023-04-17 18:37:30,384:INFO:   category_encoders: 2.6.0
2023-04-17 18:37:30,384:INFO:            lightgbm: 3.3.5
2023-04-17 18:37:30,384:INFO:               numba: 0.56.4
2023-04-17 18:37:30,384:INFO:            requests: 2.28.2
2023-04-17 18:37:30,384:INFO:          matplotlib: 3.7.1
2023-04-17 18:37:30,384:INFO:          scikitplot: 0.3.7
2023-04-17 18:37:30,384:INFO:         yellowbrick: 1.5
2023-04-17 18:37:30,384:INFO:              plotly: 5.14.1
2023-04-17 18:37:30,384:INFO:             kaleido: 0.2.1
2023-04-17 18:37:30,384:INFO:         statsmodels: 0.13.5
2023-04-17 18:37:30,384:INFO:              sktime: 0.17.1
2023-04-17 18:37:30,384:INFO:               tbats: 1.1.2
2023-04-17 18:37:30,384:INFO:            pmdarima: 2.0.3
2023-04-17 18:37:30,384:INFO:              psutil: 5.9.4
2023-04-17 18:37:30,384:INFO:PyCaret optional dependencies:
2023-04-17 18:37:30,398:INFO:                shap: Not installed
2023-04-17 18:37:30,400:INFO:           interpret: Not installed
2023-04-17 18:37:30,400:INFO:                umap: Not installed
2023-04-17 18:37:30,400:INFO:    pandas_profiling: Not installed
2023-04-17 18:37:30,400:INFO:  explainerdashboard: Not installed
2023-04-17 18:37:30,400:INFO:             autoviz: Not installed
2023-04-17 18:37:30,400:INFO:           fairlearn: Not installed
2023-04-17 18:37:30,400:INFO:             xgboost: Not installed
2023-04-17 18:37:30,400:INFO:            catboost: Not installed
2023-04-17 18:37:30,400:INFO:              kmodes: Not installed
2023-04-17 18:37:30,400:INFO:             mlxtend: Not installed
2023-04-17 18:37:30,400:INFO:       statsforecast: Not installed
2023-04-17 18:37:30,400:INFO:        tune_sklearn: Not installed
2023-04-17 18:37:30,400:INFO:                 ray: Not installed
2023-04-17 18:37:30,400:INFO:            hyperopt: Not installed
2023-04-17 18:37:30,400:INFO:              optuna: Not installed
2023-04-17 18:37:30,400:INFO:               skopt: Not installed
2023-04-17 18:37:30,400:INFO:              mlflow: Not installed
2023-04-17 18:37:30,400:INFO:              gradio: Not installed
2023-04-17 18:37:30,400:INFO:             fastapi: Not installed
2023-04-17 18:37:30,400:INFO:             uvicorn: Not installed
2023-04-17 18:37:30,400:INFO:              m2cgen: Not installed
2023-04-17 18:37:30,400:INFO:           evidently: Not installed
2023-04-17 18:37:30,400:INFO:               fugue: Not installed
2023-04-17 18:37:30,401:INFO:           streamlit: 1.21.0
2023-04-17 18:37:30,401:INFO:             prophet: Not installed
2023-04-17 18:37:30,401:INFO:None
2023-04-17 18:37:30,401:INFO:Set up data.
2023-04-17 18:37:30,406:INFO:Set up train/test split.
2023-04-17 18:37:30,413:INFO:Set up index.
2023-04-17 18:37:30,413:INFO:Set up folding strategy.
2023-04-17 18:37:30,414:INFO:Assigning column types.
2023-04-17 18:37:30,418:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-17 18:37:30,418:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,424:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,432:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,569:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:30,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:30,603:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,608:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:30,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:30,745:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-17 18:37:30,750:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,756:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:30,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:30,892:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,899:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:37:30,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,028:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-17 18:37:31,040:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,183:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,255:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,317:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-17 18:37:31,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,542:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,602:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-17 18:37:31,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,894:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-17 18:37:31,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:31,965:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-17 18:37:32,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:32,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:32,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:32,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:32,262:INFO:Preparing preprocessing pipeline...
2023-04-17 18:37:32,262:INFO:Set up simple imputation.
2023-04-17 18:37:32,266:INFO:Set up encoding of ordinal features.
2023-04-17 18:37:32,269:INFO:Set up encoding of categorical features.
2023-04-17 18:37:32,269:INFO:Set up feature normalization.
2023-04-17 18:37:32,391:INFO:Finished creating preprocessing pipeline.
2023-04-17 18:37:32,459:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-04-17 18:37:32,459:INFO:Creating final display dataframe.
2023-04-17 18:37:32,743:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape        (1070, 10)
6    Transformed test set shape         (268, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              c0b7
2023-04-17 18:37:32,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:32,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:33,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:33,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-17 18:37:33,085:INFO:setup() successfully completed in 3.03s...............
2023-04-17 18:37:33,085:INFO:Initializing create_model()
2023-04-17 18:37:33,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, estimator=gbr, fold=10, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-17 18:37:33,085:INFO:Checking exceptions
2023-04-17 18:37:33,087:INFO:Importing libraries
2023-04-17 18:37:33,087:INFO:Copying training dataset
2023-04-17 18:37:33,093:INFO:Defining folds
2023-04-17 18:37:33,093:INFO:Declaring metric variables
2023-04-17 18:37:33,093:INFO:Importing untrained model
2023-04-17 18:37:33,094:INFO:Gradient Boosting Regressor Imported successfully
2023-04-17 18:37:33,094:INFO:Starting cross validation
2023-04-17 18:37:33,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-17 18:37:45,132:INFO:Calculating mean and std
2023-04-17 18:37:45,132:INFO:Creating metrics dataframe
2023-04-17 18:37:45,135:INFO:Finalizing model
2023-04-17 18:37:45,873:INFO:Uploading results into container
2023-04-17 18:37:45,874:INFO:Uploading model into container now
2023-04-17 18:37:45,888:INFO:_master_model_container: 1
2023-04-17 18:37:45,888:INFO:_display_container: 2
2023-04-17 18:37:45,888:INFO:GradientBoostingRegressor(random_state=123)
2023-04-17 18:37:45,888:INFO:create_model() successfully completed......................................
2023-04-17 18:37:45,989:INFO:Initializing tune_model()
2023-04-17 18:37:45,989:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=10, round=4, n_iter=30, custom_grid={'learning_rate': [0.01, 0.02, 0.05], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8], 'subsample': [0.4, 0.5, 0.6, 0.7, 0.8], 'n_estimators': [100, 200.3, 400, 500, 600]}, optimize=RMSE, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>)
2023-04-17 18:37:45,989:INFO:Checking exceptions
2023-04-17 18:37:45,993:INFO:Copying training dataset
2023-04-17 18:37:45,996:INFO:Checking base model
2023-04-17 18:37:45,996:INFO:Base model : Gradient Boosting Regressor
2023-04-17 18:37:45,997:INFO:Declaring metric variables
2023-04-17 18:37:45,997:INFO:Defining Hyperparameters
2023-04-17 18:37:46,118:INFO:custom_grid: {'actual_estimator__learning_rate': [0.01, 0.02, 0.05], 'actual_estimator__max_depth': [1, 2, 3, 4, 5, 6, 7, 8], 'actual_estimator__subsample': [0.4, 0.5, 0.6, 0.7, 0.8], 'actual_estimator__n_estimators': [100, 200.3, 400, 500, 600]}
2023-04-17 18:37:46,118:INFO:Tuning with n_jobs=-1
2023-04-17 18:37:46,118:INFO:Initializing RandomizedSearchCV
2023-04-17 18:39:06,596:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-17 18:39:45,494:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
50 fits failed out of a total of 300.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
50 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_gb.py", line 420, in fit
    self._validate_params()
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of GradientBoostingRegressor must be an int in the range [1, inf). Got 200.3 instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-04-17 18:39:45,500:WARNING:C:\Users\aboli\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [           nan -8266.13508125 -6325.52283722            nan
 -5524.08131975 -6145.05493581 -4740.77930626 -4662.82752541
            nan -5576.98682335 -5196.9411431  -4690.00873571
 -4682.97402455 -4697.685413              nan -5622.34435494
 -5227.96958143 -5224.91345071 -6161.90479791 -5607.95367476
 -4796.87705555 -6128.27274871 -4787.14842839            nan
 -5349.58560424 -4834.11508154 -4845.71011433 -4952.81928436
 -4924.67466185 -5419.81098671]
  warnings.warn(

2023-04-17 18:39:46,116:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 600, 'actual_estimator__max_depth': 2, 'actual_estimator__learning_rate': 0.01}
2023-04-17 18:39:46,117:INFO:Hyperparameter search completed
2023-04-17 18:39:46,117:INFO:SubProcess create_model() called ==================================
2023-04-17 18:39:46,117:INFO:Initializing create_model()
2023-04-17 18:39:46,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A67BB2AB00>, model_only=True, return_train_score=False, kwargs={'subsample': 0.6, 'n_estimators': 600, 'max_depth': 2, 'learning_rate': 0.01})
2023-04-17 18:39:46,117:INFO:Checking exceptions
2023-04-17 18:39:46,117:INFO:Importing libraries
2023-04-17 18:39:46,118:INFO:Copying training dataset
2023-04-17 18:39:46,121:INFO:Defining folds
2023-04-17 18:39:46,122:INFO:Declaring metric variables
2023-04-17 18:39:46,122:INFO:Importing untrained model
2023-04-17 18:39:46,122:INFO:Declaring custom model
2023-04-17 18:39:46,122:INFO:Gradient Boosting Regressor Imported successfully
2023-04-17 18:39:46,122:INFO:Starting cross validation
2023-04-17 18:39:46,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-17 18:39:50,416:INFO:Calculating mean and std
2023-04-17 18:39:50,417:INFO:Creating metrics dataframe
2023-04-17 18:39:50,419:INFO:Finalizing model
2023-04-17 18:39:51,180:INFO:Uploading results into container
2023-04-17 18:39:51,181:INFO:Uploading model into container now
2023-04-17 18:39:51,181:INFO:_master_model_container: 2
2023-04-17 18:39:51,181:INFO:_display_container: 3
2023-04-17 18:39:51,181:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=2, n_estimators=600,
                          random_state=123, subsample=0.6)
2023-04-17 18:39:51,182:INFO:create_model() successfully completed......................................
2023-04-17 18:39:51,281:INFO:SubProcess create_model() end ==================================
2023-04-17 18:39:51,281:INFO:choose_better activated
2023-04-17 18:39:51,282:INFO:SubProcess create_model() called ==================================
2023-04-17 18:39:51,282:INFO:Initializing create_model()
2023-04-17 18:39:51,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-17 18:39:51,282:INFO:Checking exceptions
2023-04-17 18:39:51,283:INFO:Importing libraries
2023-04-17 18:39:51,283:INFO:Copying training dataset
2023-04-17 18:39:51,287:INFO:Defining folds
2023-04-17 18:39:51,287:INFO:Declaring metric variables
2023-04-17 18:39:51,288:INFO:Importing untrained model
2023-04-17 18:39:51,288:INFO:Declaring custom model
2023-04-17 18:39:51,288:INFO:Gradient Boosting Regressor Imported successfully
2023-04-17 18:39:51,288:INFO:Starting cross validation
2023-04-17 18:39:51,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-17 18:39:54,716:INFO:Calculating mean and std
2023-04-17 18:39:54,716:INFO:Creating metrics dataframe
2023-04-17 18:39:54,718:INFO:Finalizing model
2023-04-17 18:39:55,461:INFO:Uploading results into container
2023-04-17 18:39:55,462:INFO:Uploading model into container now
2023-04-17 18:39:55,462:INFO:_master_model_container: 3
2023-04-17 18:39:55,462:INFO:_display_container: 4
2023-04-17 18:39:55,463:INFO:GradientBoostingRegressor(random_state=123)
2023-04-17 18:39:55,463:INFO:create_model() successfully completed......................................
2023-04-17 18:39:55,555:INFO:SubProcess create_model() end ==================================
2023-04-17 18:39:55,556:INFO:GradientBoostingRegressor(random_state=123) result for RMSE is 4810.8326
2023-04-17 18:39:55,557:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=2, n_estimators=600,
                          random_state=123, subsample=0.6) result for RMSE is 4662.8275
2023-04-17 18:39:55,557:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=2, n_estimators=600,
                          random_state=123, subsample=0.6) is best model
2023-04-17 18:39:55,557:INFO:choose_better completed
2023-04-17 18:39:55,565:INFO:_master_model_container: 3
2023-04-17 18:39:55,566:INFO:_display_container: 3
2023-04-17 18:39:55,566:INFO:GradientBoostingRegressor(learning_rate=0.01, max_depth=2, n_estimators=600,
                          random_state=123, subsample=0.6)
2023-04-17 18:39:55,566:INFO:tune_model() successfully completed......................................
2023-04-17 18:39:55,890:INFO:Initializing predict_model()
2023-04-17 18:39:55,890:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002A67D107760>)
2023-04-17 18:39:55,890:INFO:Checking exceptions
2023-04-17 18:39:55,890:INFO:Preloading libraries
2023-04-17 18:39:56,243:INFO:Initializing evaluate_model()
2023-04-17 18:39:56,244:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-17 18:39:56,590:INFO:Initializing plot_model()
2023-04-17 18:39:56,590:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, system=True)
2023-04-17 18:39:56,591:INFO:Checking exceptions
2023-04-17 18:39:56,594:INFO:Preloading libraries
2023-04-17 18:39:56,602:INFO:Copying training dataset
2023-04-17 18:39:56,602:INFO:Plot type: pipeline
2023-04-17 18:39:57,066:INFO:Initializing finalize_model()
2023-04-17 18:39:57,066:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, estimator=GradientBoostingRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-17 18:39:57,066:INFO:Finalizing GradientBoostingRegressor(random_state=123)
2023-04-17 18:39:57,070:INFO:Initializing create_model()
2023-04-17 18:39:57,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A67BAC68C0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-17 18:39:57,070:INFO:Checking exceptions
2023-04-17 18:39:57,071:INFO:Importing libraries
2023-04-17 18:39:57,071:INFO:Copying training dataset
2023-04-17 18:39:57,071:INFO:Defining folds
2023-04-17 18:39:57,071:INFO:Declaring metric variables
2023-04-17 18:39:57,072:INFO:Importing untrained model
2023-04-17 18:39:57,072:INFO:Declaring custom model
2023-04-17 18:39:57,073:INFO:Gradient Boosting Regressor Imported successfully
2023-04-17 18:39:57,074:INFO:Cross validation set to False
2023-04-17 18:39:57,074:INFO:Fitting Model
2023-04-17 18:39:57,226:INFO:Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2023-04-17 18:39:57,226:INFO:create_model() successfully completed......................................
2023-04-17 18:39:57,316:INFO:_master_model_container: 3
2023-04-17 18:39:57,316:INFO:_display_container: 4
2023-04-17 18:39:57,385:INFO:Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2023-04-17 18:39:57,386:INFO:finalize_model() successfully completed......................................
2023-04-17 18:39:57,580:INFO:Initializing save_model()
2023-04-17 18:39:57,581:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), model_name=C:\Users\aboli\OneDrive\Desktop\ML_project\insurance_prediction, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-17 18:39:57,581:INFO:Adding model into prep_pipe
2023-04-17 18:39:57,592:WARNING:Only Model saved as it was a pipeline.
2023-04-17 18:39:57,603:INFO:C:\Users\aboli\OneDrive\Desktop\ML_project\insurance_prediction.pkl saved in current working directory
2023-04-17 18:39:57,656:INFO:Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2023-04-17 18:39:57,656:INFO:save_model() successfully completed......................................
2023-04-17 18:40:59,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:40:59,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:40:59,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:40:59,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:41:01,494:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-17 18:41:44,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:41:44,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:41:44,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:41:44,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:41:45,386:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-17 18:41:46,748:INFO:Initializing load_model()
2023-04-17 18:41:46,749:INFO:Initializing load_model()
2023-04-17 18:41:46,749:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 18:41:46,750:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 18:41:56,776:INFO:Initializing load_model()
2023-04-17 18:41:56,777:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 18:41:56,888:INFO:Initializing predict_model()
2023-04-17 18:41:56,888:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002440CDF8820>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024428B03F40>)
2023-04-17 18:41:56,890:INFO:Checking exceptions
2023-04-17 18:41:56,891:INFO:Preloading libraries
2023-04-17 18:41:56,892:INFO:Set up data.
2023-04-17 18:41:56,896:INFO:Set up index.
2023-04-17 18:46:37,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:46:38,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:46:38,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:46:38,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-17 18:46:39,136:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-17 18:46:40,508:INFO:Initializing load_model()
2023-04-17 18:46:40,508:INFO:Initializing load_model()
2023-04-17 18:46:40,509:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 18:46:40,510:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 18:46:49,237:INFO:Initializing load_model()
2023-04-17 18:46:49,238:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 18:46:49,384:INFO:Initializing predict_model()
2023-04-17 18:46:49,385:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E8B6EF3CA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E8B71FF910>)
2023-04-17 18:46:49,386:INFO:Checking exceptions
2023-04-17 18:46:49,386:INFO:Preloading libraries
2023-04-17 18:46:49,386:INFO:Set up data.
2023-04-17 18:46:49,393:INFO:Set up index.
2023-04-17 18:47:31,443:INFO:Initializing load_model()
2023-04-17 18:47:31,445:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 18:48:35,935:INFO:Initializing load_model()
2023-04-17 18:48:35,936:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 19:44:54,476:INFO:Initializing load_model()
2023-04-17 19:44:54,484:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 19:46:50,857:INFO:Initializing load_model()
2023-04-17 19:46:50,859:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 19:46:50,971:INFO:Initializing predict_model()
2023-04-17 19:46:50,971:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E89B8ECF40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E89B8DA950>)
2023-04-17 19:46:50,972:INFO:Checking exceptions
2023-04-17 19:46:50,972:INFO:Preloading libraries
2023-04-17 19:46:50,975:INFO:Set up data.
2023-04-17 19:46:50,984:INFO:Set up index.
2023-04-17 20:05:07,421:INFO:Initializing load_model()
2023-04-17 20:05:07,422:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 20:05:44,060:INFO:Initializing load_model()
2023-04-17 20:05:44,061:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 20:05:44,213:INFO:Initializing predict_model()
2023-04-17 20:05:44,214:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E8B6F717B0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E89AD935B0>)
2023-04-17 20:05:44,215:INFO:Checking exceptions
2023-04-17 20:05:44,215:INFO:Preloading libraries
2023-04-17 20:05:44,215:INFO:Set up data.
2023-04-17 20:05:44,221:INFO:Set up index.
2023-04-17 21:38:40,541:INFO:Initializing load_model()
2023-04-17 21:38:40,545:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 21:41:41,408:INFO:Initializing load_model()
2023-04-17 21:41:41,409:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 21:42:14,375:INFO:Initializing load_model()
2023-04-17 21:42:14,376:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 22:26:47,385:INFO:Initializing load_model()
2023-04-17 22:26:47,387:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-17 22:47:48,366:INFO:Initializing load_model()
2023-04-17 22:47:48,368:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:24:02,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 09:24:02,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 09:24:02,421:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 09:24:02,421:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-18 09:24:04,475:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-18 09:24:06,306:INFO:Initializing load_model()
2023-04-18 09:24:06,306:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:24:42,225:INFO:Initializing load_model()
2023-04-18 09:24:42,227:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:24:42,325:INFO:Initializing predict_model()
2023-04-18 09:24:42,325:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193BE623F10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193DA55F910>)
2023-04-18 09:24:42,325:INFO:Checking exceptions
2023-04-18 09:24:42,325:INFO:Preloading libraries
2023-04-18 09:24:42,334:INFO:Set up data.
2023-04-18 09:24:42,334:INFO:Set up index.
2023-04-18 09:31:20,819:INFO:Initializing load_model()
2023-04-18 09:31:20,819:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:47:55,813:INFO:Initializing load_model()
2023-04-18 09:47:55,813:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:48:08,215:INFO:Initializing load_model()
2023-04-18 09:48:08,216:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:48:08,303:INFO:Initializing predict_model()
2023-04-18 09:48:08,304:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193DABA4700>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193DA9B70A0>)
2023-04-18 09:48:08,304:INFO:Checking exceptions
2023-04-18 09:48:08,306:INFO:Preloading libraries
2023-04-18 09:48:08,306:INFO:Set up data.
2023-04-18 09:48:08,312:INFO:Set up index.
2023-04-18 09:48:18,353:INFO:Initializing load_model()
2023-04-18 09:48:18,355:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:48:18,438:INFO:Initializing predict_model()
2023-04-18 09:48:18,439:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193DABA45E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193DA9B76D0>)
2023-04-18 09:48:18,441:INFO:Checking exceptions
2023-04-18 09:48:18,441:INFO:Preloading libraries
2023-04-18 09:48:18,442:INFO:Set up data.
2023-04-18 09:48:18,447:INFO:Set up index.
2023-04-18 09:48:21,675:INFO:Initializing load_model()
2023-04-18 09:48:21,676:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 09:48:21,752:INFO:Initializing predict_model()
2023-04-18 09:48:21,752:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193DA7B8970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193DA9B7250>)
2023-04-18 09:48:21,752:INFO:Checking exceptions
2023-04-18 09:48:21,752:INFO:Preloading libraries
2023-04-18 09:48:21,753:INFO:Set up data.
2023-04-18 09:48:21,758:INFO:Set up index.
2023-04-18 10:21:17,372:INFO:Initializing load_model()
2023-04-18 10:21:17,373:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 10:28:06,831:INFO:Initializing load_model()
2023-04-18 10:28:06,831:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 10:28:06,931:INFO:Initializing predict_model()
2023-04-18 10:28:06,931:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193DA7BBC70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193BE632B90>)
2023-04-18 10:28:06,932:INFO:Checking exceptions
2023-04-18 10:28:06,932:INFO:Preloading libraries
2023-04-18 10:28:06,932:INFO:Set up data.
2023-04-18 10:28:06,938:INFO:Set up index.
2023-04-18 10:28:44,080:INFO:Initializing load_model()
2023-04-18 10:28:44,080:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 10:28:44,163:INFO:Initializing predict_model()
2023-04-18 10:28:44,163:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193DABA6650>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193DA9B7910>)
2023-04-18 10:28:44,165:INFO:Checking exceptions
2023-04-18 10:28:44,165:INFO:Preloading libraries
2023-04-18 10:28:44,165:INFO:Set up data.
2023-04-18 10:28:44,171:INFO:Set up index.
2023-04-18 10:29:14,640:INFO:Initializing load_model()
2023-04-18 10:29:14,640:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 10:29:14,725:INFO:Initializing predict_model()
2023-04-18 10:29:14,725:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193DABA49D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193DA9B7910>)
2023-04-18 10:29:14,725:INFO:Checking exceptions
2023-04-18 10:29:14,725:INFO:Preloading libraries
2023-04-18 10:29:14,725:INFO:Set up data.
2023-04-18 10:29:14,743:INFO:Set up index.
2023-04-18 10:42:10,387:INFO:Initializing load_model()
2023-04-18 10:42:10,387:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 11:38:35,234:INFO:Initializing load_model()
2023-04-18 11:38:35,242:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 13:52:02,067:INFO:Initializing load_model()
2023-04-18 13:52:02,068:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 14:29:48,700:INFO:Initializing load_model()
2023-04-18 14:29:48,700:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 17:31:55,705:INFO:Initializing load_model()
2023-04-18 17:31:55,707:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 17:33:05,977:INFO:Initializing load_model()
2023-04-18 17:33:05,978:INFO:load_model(model_name=insurance_prediction, platform=None, authentication=None, verbose=True)
2023-04-18 17:33:06,080:INFO:Initializing predict_model()
2023-04-18 17:33:06,080:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000193DABA71F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\aboli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000193DA9B7520>)
2023-04-18 17:33:06,082:INFO:Checking exceptions
2023-04-18 17:33:06,082:INFO:Preloading libraries
2023-04-18 17:33:06,085:INFO:Set up data.
2023-04-18 17:33:06,094:INFO:Set up index.
